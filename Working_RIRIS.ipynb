{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear predictive border padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import lfilter, lfiltic\n",
    "from spectrum import arburg\n",
    "\n",
    "\n",
    "def arburg_extrap(signal, extr_length, order=2):\n",
    "    \"\"\" \n",
    "    Given a \"signal\", it concatenates the extrapolation at the end of the signal of length \"extr_length\"\n",
    "    _______signal________ + ___extrap___\n",
    "\n",
    "    The extrapolation is calculated using a 1-D digital filter (filter in MATLAB or scipy.signal.lfilter in Python)\n",
    "    The parameters for the filter comes from an autoregressive Burg's method (arburg) with order \"order\"    \n",
    "\n",
    "    Example:\n",
    "\n",
    "    signal = np.arange(10)\n",
    "    print(f\" signal: {signal}\")\n",
    "    extrap_forward = arburg_extrap(signal, 3, 2)\n",
    "    print(f\" extrap_forward: {extrap_forward}\")\n",
    "    extrap_backward = arburg_extrap(extrap_forward[::-1], 3, 2)[::-1]\n",
    "    print(f\" extrap_backward: {extrap_backward}\")\n",
    "    \"\"\"\n",
    "    a0, _, _ = arburg(signal, order)\n",
    "    a = np.concatenate(([1], a0)) # add a 1 at the begining of a0 to look like on Matlab\n",
    "\n",
    "    last_points = signal[-order:] #last points, number of points == order\n",
    "    last_points = last_points[::-1] # give the \"last points\" in reverse order, the oldest the first (as lfilter wants the x and y)\n",
    "\n",
    "    Z = lfiltic(b=1, a=a, y=last_points, x=None) # Initial conditions for the lfilter\n",
    "    yzi, _ = lfilter(b=np.array([1]), a=a, x=np.zeros(extr_length), zi=Z)\n",
    "\n",
    "    extrap = np.concatenate((signal, yzi.real))\n",
    "\n",
    "    return extrap\n",
    "\n",
    "\n",
    "def lpbp1D(signalIn, dL, dR, order=2):\n",
    "    \"\"\"\n",
    "    LPBP1D 1D Linear Predictive Border Padding\n",
    "    \n",
    "    This function extrapolates linear microphone array data by means of\n",
    "    designing and applying filters with AR prediction coefficients.\n",
    "    \n",
    "    Parameters:\n",
    "    signalIn : array-like (size N)\n",
    "        1D input signal\n",
    "    dL, dR,: int\n",
    "        Number of samples added before and after the signal\n",
    "    order : int\n",
    "        Order of the filter (\"number of Fourier peaks\")\n",
    "        \n",
    "    Returns:\n",
    "    signalOut : array-like\n",
    "        Extrapolated signal. \n",
    "        1D array resulting of a concatenation of [dL, N, dR] samples\n",
    "        dN being extrapolated parts.\n",
    "    \"\"\"\n",
    "    \n",
    "    signal_extr_forw = arburg_extrap(signalIn, extr_length=dR, order=order) # extrapolate forward in time\n",
    "    signalOut = arburg_extrap(signal_extr_forw[::-1], extr_length=dL, order=order)[::-1] # flip the signal and extrapolate to extrapolate backwards in time\n",
    "    \n",
    "    return signalOut\n",
    "\n",
    "\n",
    "# N = orig_image.shape[1]\n",
    "# dN = 14\n",
    "\n",
    "# # image_under = orig_image*mask0\n",
    "# image_under = orig_image\n",
    "\n",
    "\n",
    "# y = image_under[0, :]\n",
    "# extrap_signal = lpbp1D(y, dN, 2)\n",
    "\n",
    "# x = np.arange(dN, N+dN)\n",
    "# plt.plot(x, y, linewidth=4, c='b')\n",
    "# plt.plot(extrap_signal, c='r')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operaciones con imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def next_power_of_2(n):\n",
    "    \"\"\"Return the next power of 2 greater than or equal to n.\"\"\"\n",
    "    return 1 if n == 0 else 2**int(np.ceil(np.log2(n)))\n",
    "\n",
    "\n",
    "class ImageOps:\n",
    "    \"\"\" \n",
    "    Lo uso para crear un objeto imagen con un mÃ©todo:\n",
    "        expand_image() \n",
    "            que pueda expandirse en la imagen extrapolada\n",
    "        recover_image()\n",
    "            que devuelva la imagen original\n",
    "        mask_image()\n",
    "            que devuelva la imagen enmascarada     \n",
    "    \"\"\"\n",
    "    def __init__(self, image_shape, mask, mode=\"pad\", extrap_shape=None) -> None:\n",
    "        # self.image = image\n",
    "        self.orig_shape = image_shape\n",
    "        self.mask = mask\n",
    "        self.state = \"original\"\n",
    "        self.mode = mode\n",
    "\n",
    "        m0, n0 = image_shape\n",
    "        # Si extrap_shape es None, usar next_power_of_2 para calcular m y n\n",
    "        if extrap_shape is None:\n",
    "            m = next_power_of_2(m0)\n",
    "            n = next_power_of_2(n0)\n",
    "        else:\n",
    "            m, n = extrap_shape\n",
    "\n",
    "        # Asignar extrap_shape basado en los valores calculados o proporcionados\n",
    "        self.extrap_shape = (m, n)\n",
    "\n",
    "        self.up_pad = max((m - m0) // 2, 0)\n",
    "        self.down_pad = max(m - self.up_pad - m0, 0)\n",
    "        self.left_pad = max((n - n0) // 2, 0)\n",
    "        self.right_pad = max(n - self.left_pad - n0, 0)\n",
    "\n",
    "    def expand_image(self, image):\n",
    "        \"\"\"\n",
    "        Extrapolate an image to the next power of 2 dimensions or specified padding.\n",
    "        Parameters:\n",
    "        image (np.array): 2D array to be extrapolated.\n",
    "        flag_extrap (int): Currently unused. Reserved for future use.\n",
    "\n",
    "        Returns:\n",
    "        np.array: Padded 2D array.\n",
    "        \"\"\"\n",
    "\n",
    "        if image.shape == self.extrap_shape:\n",
    "            return image\n",
    "        \n",
    "        elif self.mode == \"extrapolate\":\n",
    "\n",
    "            T = image.shape[0]\n",
    "            M = self.extrap_shape[1]            \n",
    "\n",
    "            image_ext = np.zeros((T, M))\n",
    "            for tt in range(T):  # execute linear predictive border padding\n",
    "                image_ext[tt, :] = lpbp1D(image[tt, :], dL=self.left_pad, dR=self.right_pad, order=2)\n",
    "\n",
    "            # Pad vertically with 0s\n",
    "            pad_width = ((self.up_pad, self.down_pad), (0, 0))\n",
    "            padded_image = np.pad(image_ext, pad_width, mode='constant', constant_values=0)\n",
    "\n",
    "            self.state = \"expanded\"\n",
    "\n",
    "            return padded_image\n",
    "        \n",
    "        else:   \n",
    "            # Padding the 2D array with zeros\n",
    "            pad_width = ((self.up_pad, self.down_pad), (self.left_pad, self.right_pad))\n",
    "            padded_image = np.pad(image, pad_width, mode='constant', constant_values=0)\n",
    "\n",
    "            self.state = \"expanded\"\n",
    "\n",
    "            return padded_image\n",
    "    \n",
    "        \n",
    "    def recover_image(self, image):\n",
    "        \"\"\" Take the original image from the extrapolated image \"\"\"\n",
    "        if image.shape == self.extrap_shape:\n",
    "            m, n = self.extrap_shape\n",
    "            rec_image = image[self.up_pad: m-self.down_pad, self.left_pad:n-self.right_pad]\n",
    "            self.state = \"original\"\n",
    "            return rec_image\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "\n",
    "    def get_mask(self, image):\n",
    "        if image.shape == self.orig_shape:\n",
    "            return self.mask\n",
    "        \n",
    "        # Pad the mask to match the extrapolated image dimensions\n",
    "        if self.mask.ndim == 1:\n",
    "            pad_width = (self.left_pad, self.right_pad)\n",
    "        elif self.mask.ndim == 2:\n",
    "            pad_width = ((0, 0), (self.left_pad, self.right_pad))\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported mask dimension: {}\".format(self.mask.ndim))\n",
    "\n",
    "        if self.mode == \"extrapolate\":\n",
    "            pad_values = 1\n",
    "        else:\n",
    "            pad_values = 0\n",
    "        \n",
    "        padded_mask = np.pad(self.mask, pad_width, mode='constant', constant_values=pad_values)\n",
    "        return padded_mask\n",
    "\n",
    "        \n",
    "    def mask_image(self, image):\n",
    "        return self.get_mask(image) * image\n",
    "            \n",
    "\n",
    "orig_image = np.ceil(10*np.random.rand(5,5))\n",
    "mask = np.ones(5)\n",
    "mask[3] = 0\n",
    "\n",
    "Sk = np.ones((8,8,12))\n",
    "extr_size = Sk.shape[:2]\n",
    "\n",
    "imOps = ImageOps(orig_image.shape, mask, extrap_shape=(8,10), mode=\"extrapolate\") \n",
    "# imOps = ImageOps(orig_image.shape, mask, extrap_shape=(0,10), mode=\"pad\") \n",
    "im_ex = imOps.expand_image(orig_image)\n",
    "\n",
    "mask_exp = imOps.get_mask(im_ex)\n",
    "mask_ori = imOps.get_mask(orig_image)\n",
    "\n",
    "print(f\"orig_image\")\n",
    "print(orig_image)\n",
    "\n",
    "print(\"extrapolated image\")\n",
    "print(im_ex)\n",
    "\n",
    "\n",
    "print(\"mask extrap\")\n",
    "print(mask_exp)\n",
    "\n",
    "print(\"mask\")\n",
    "print(mask_ori)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ffst(image, Sk_func_dict):\n",
    "    \"\"\"\n",
    "    image (M,N)\n",
    "    Sk_func_dict (M,N,d) (Fourier Space)\n",
    "    alpha (coefs in physical space of Sk functions)\n",
    "    \"\"\"\n",
    "\n",
    "    F2d_im = np.fft.fft2(image) \n",
    "    F2d_im = np.fft.fftshift(F2d_im) # order coefs from negative to positive in axes=(0,1)\n",
    "\n",
    "    # Proyection in Fourier space for all functions in dictionary\n",
    "    Fproyection = Sk_func_dict * F2d_im[:, :, np.newaxis]\n",
    "    Fproyection = np.fft.ifftshift(Fproyection, axes=(0,1))  # no ifftshift in 3rd axis\n",
    "    \n",
    "    # alpha contains the projection of the image in each decomposition/scale in physical space\n",
    "    alpha = np.fft.ifft2(Fproyection, axes=(0, 1)).real  # by default, fft2 operates in the last 2 axes\n",
    "\n",
    "    return alpha\n",
    "\n",
    "\n",
    "def iffst(alpha, Sk_func_dict):\n",
    "    \"\"\"\n",
    "    alpha (M,N, d): coefs in phys space of the Sk functions\n",
    "    Sk_func_dict (M,N,d): Functions/kernels in dictionary\n",
    "    rec_image: reconstruction of the image in physical space\n",
    "    \"\"\"\n",
    "\n",
    "    # Change alpha to Fourier space\n",
    "    F_alpha = np.fft.fft2(alpha, axes=(0,1))\n",
    "    F_alpha = np.fft.fftshift(F_alpha, axes=(0,1))\n",
    "\n",
    "    # Multiply coeficients by the functions in dictionary (in Fourier)\n",
    "    sum_alpha = np.sum( F_alpha*Sk_func_dict , axis=2) # sum up decompositions\n",
    "    sum_alpha = np.fft.ifftshift(sum_alpha) # axis=(0,1) since axis=2 has been reduced with the sum\n",
    "    \n",
    "    # Change from Fourier to physical space\n",
    "    rec_image = np.fft.ifft2(sum_alpha).real # recover RIR image\n",
    " \n",
    "    return rec_image\n",
    "\n",
    "\n",
    "def wthresh(x, thresh):\n",
    "    return np.sign(x) * np.maximum(np.abs(x) - thresh, 0)\n",
    "\n",
    "\n",
    "def common_operations(image, mask, Sk, alpha, threshold):\n",
    "    # Recupera la imagen de las coeficientes\n",
    "    rec_image = mask * iffst(alpha, Sk)\n",
    "    # Calcula la diferencia entre la imagen original y la recuperada\n",
    "    diff_image = mask * (image - rec_image)\n",
    "    # Proyecta la diferencia en el espacio de Fourier\n",
    "    diff_alpha = ffst(diff_image, Sk)\n",
    "\n",
    "    # Actualiza la seÃ±al y aplica el umbral\n",
    "    signal = alpha + diff_alpha\n",
    "    # thresh = beta * np.max(np.abs(alpha))\n",
    "\n",
    "    # Aplica el umbral suave a la seÃ±al\n",
    "    alpha_new = wthresh(signal, threshold)\n",
    "\n",
    "    # Calcula las mÃ©tricas de esparcidad y residuo\n",
    "    eta = np.linalg.norm(alpha_new.ravel(), 1)       # ||alpha_new||_1\n",
    "\n",
    "    rec_image_new = mask * iffst(alpha_new, Sk)\n",
    "    diff_image_new = mask * (image - rec_image_new)\n",
    "    rho = np.linalg.norm(diff_image_new.ravel(), 2)  # || diff_image ||_2\n",
    "\n",
    "    return alpha_new, eta, rho\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_set = np.logspace(-2.5, -1, 50)\n",
    "\n",
    "def computePareto(image, mask, Sk, beta_set):\n",
    "    from scipy.interpolate import splrep, splev, splder\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    # preallocate:\n",
    "    # eta = np.zeros((len(beta_set), 1))  # sparsity norm\n",
    "    # rho = np.zeros((len(beta_set), 1))  # residual norm\n",
    "    eta = np.zeros_like(beta_set)  # sparsity norm\n",
    "    rho = np.zeros_like(beta_set)  # residual norm\n",
    "\n",
    "    image = mask*image\n",
    "    alpha0 = ffst(image, Sk)  # initialize solution vector\n",
    "    norm_inf_alpha0 = np.linalg.norm(alpha0.ravel(), np.inf)\n",
    "\n",
    "    for bb, beta in enumerate(beta_set):\n",
    "        threshold = beta * norm_inf_alpha0\n",
    "        _, eta[bb], rho[bb] = common_operations(image, mask, Sk, alpha0, threshold)\n",
    "        print(f'Pareto iteration {bb+1}/{len(beta_set)}.')\n",
    "\n",
    "    # InterpolaciÃ³n spline cÃºbica para eta y rho\n",
    "    eta_sp = splrep(beta_set, np.log(eta))\n",
    "    rho_sp = splrep(beta_set, np.log(rho))\n",
    "\n",
    "    # Derivadas primera y segunda de eta y rho\n",
    "    eta_prime1 = splev(beta_set, splder(eta_sp, 1)) # eta'\n",
    "    eta_prime2 = splev(beta_set, splder(eta_sp, 2)) # eta''\n",
    "    rho_prime1 = splev(beta_set, splder(rho_sp, 1)) # rho'\n",
    "    rho_prime2 = splev(beta_set, splder(rho_sp, 2)) # rho''\n",
    "\n",
    "    # CÃ¡lculo de la curva J\n",
    "    Jcurve = (rho_prime2 * eta_prime1 - rho_prime1 * eta_prime2) / (rho_prime1**2 + eta_prime1**2)**1.5\n",
    "\n",
    "    # Encontrar el beta Ã³ptimo\n",
    "    idx_max_curv = np.argmax(Jcurve)\n",
    "    beta_star = beta_set[idx_max_curv]\n",
    "\n",
    "    # Graficar la funciÃ³n de curvatura y la curva L\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    axes[0].plot(np.log(rho), np.log(eta), 'ko', linewidth=2, markersize=8)\n",
    "    axes[0].axvline(np.log(rho[idx_max_curv]), color='r', linestyle='--', linewidth=2)\n",
    "    axes[0].axhline(np.log(eta[idx_max_curv]), color='r', linestyle='--', linewidth=2)\n",
    "    axes[0].set_xlabel(r'$\\rho(\\beta) = \\| \\hat{\\mathbf{y}} - \\mathbf{\\Phi}\\alpha \\|_2$', fontsize=20, labelpad=10)\n",
    "    axes[0].set_ylabel(r'$\\eta(\\beta) = \\| \\alpha \\|_1$', fontsize=20, labelpad=10)\n",
    "    axes[0].set_title('L-curve', fontsize=22)\n",
    "    axes[0].tick_params(axis='both', which='major', labelsize=20)\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    axes[1].semilogx(beta_set, Jcurve, 'ko', linewidth=2, markersize=8)\n",
    "    axes[1].set_xlabel(r'$\\beta$', fontsize=20, labelpad=10)\n",
    "    axes[1].set_ylabel(r'$\\mathcal{J}(\\beta)$', fontsize=20, labelpad=10)\n",
    "    axes[1].set_title('Curvature Function', fontsize=22)\n",
    "    axes[1].tick_params(axis='both', which='major', labelsize=20)\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return beta_star, Jcurve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ista(image, mask, Sk, beta, epsilon, max_iterations=15 ):\n",
    "\n",
    "    # Initialize solution vector \n",
    "    image = mask*image\n",
    "    alpha = ffst(image, Sk) # here, alpha = alpha0\n",
    "\n",
    "    # Decreasing thresholds: C*zeta0 == C[i] * (beta * ||alpha_0||_inf)\n",
    "    zeta0 = beta * np.linalg.norm(alpha.ravel(), np.inf) # beta * ||alpha_0||_inf\n",
    "    C = np.linspace(1, epsilon / beta, max_iterations + 1)\n",
    "\n",
    "    # Initial residual norm\n",
    "    rec_image = mask * iffst(alpha, Sk)\n",
    "    diff_image = mask * (image - rec_image)\n",
    "    res_norm = np.linalg.norm(diff_image.ravel()) \n",
    "\n",
    "    its = 0\n",
    "    while res_norm > epsilon and its < max_iterations:\n",
    "        its += 1\n",
    "        alpha, _, res_norm = common_operations(image, mask, Sk, alpha, threshold = C[its]*zeta0)\n",
    "        print(f'Iteration no. {its}/{max_iterations}, res_norm: {res_norm}')\n",
    "\n",
    "    print('Interpolating image from thresholded coefficients...')\n",
    "    print('\\n---------------- INTERPOLATION DONE! ----------------\\n')\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_DB_ZEA(path):\n",
    "    import pymatreader as pymat\n",
    "    #Load data\n",
    "    RIR=[]\n",
    "    RIR = pymat.read_mat(path)[\"out\"][\"image\"]\n",
    "    fs = pymat.read_mat(path)[\"out\"][\"fs\"] # Hz\n",
    "    \n",
    "    T, M = RIR.shape\n",
    "    \n",
    "    x0 = 0.0\n",
    "    dx = 0.03 # m\n",
    "    x = np.arange(0,M).reshape((1,M))*dx + x0\n",
    "\n",
    "    t0 = 0.0\n",
    "    dt = 1.0/fs # s\n",
    "    t = np.arange(0,T).reshape((T,1))*dt + t0\n",
    "    return RIR, x, t\n",
    "\n",
    "def rand_downsamp_RIR(shape, ratio_t=1, ratio_x=0.5):\n",
    "    import random\n",
    "    # choose a ratio of samples in time/space from RIR\n",
    "    # random choice\n",
    "    T, M = shape\n",
    "    tsamples = int(T*ratio_t)\n",
    "    xMics  = int(M*ratio_x)\n",
    "\n",
    "    id_T = np.sort(random.sample(range(0,T), tsamples)) # rows to take\n",
    "    id_X = np.sort(random.sample(range(0,M), xMics)) # cols to take\n",
    "\n",
    "    mask_T = np.zeros([T, 1], dtype=bool)\n",
    "    mask_X = np.zeros([1, M], dtype=bool)\n",
    "\n",
    "    mask_T[id_T,0] = True\n",
    "    mask_X[0,id_X] = True\n",
    "\n",
    "    return mask_X, mask_T\n",
    "\n",
    "def load_sk(folder, file, build_dict):\n",
    "\n",
    "    file_path = os.path.join(folder, file)\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        print(\"Loading dictionary\")\n",
    "        print(file_path)\n",
    "        Sk = sio.loadmat(file_path)['Psi']\n",
    "\n",
    "    elif build_dict['Sk_type']==\"boostlet\":\n",
    "        N=build_dict[\"N\"]\n",
    "        S=build_dict[\"S\"]\n",
    "        n_thetas=build_dict[\"n_thetas\"]\n",
    "\n",
    "        print(f\"Generating boostlet dictionary. N={N}, S={S}, n_thetas={n_thetas}\")\n",
    "        a_grid = 2 ** np.arange(S)\n",
    "        theta_grid = np.linspace(-np.pi/2, np.pi/2, n_thetas)\n",
    "        Sk = get_boostlets_dict(N, a_grid, theta_grid)\n",
    "\n",
    "    return Sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sio\n",
    "from boostlets_mod import get_boostlets_dict\n",
    "\n",
    "\n",
    "room = \"Balder\"\n",
    "# Sk_type = \"shearlet\"\n",
    "Sk_type = \"boostlet\"\n",
    "S = 2 # number of decomposition scales\n",
    "ratio_undersampling = 0.3\n",
    "\n",
    "extrap_mode = \"extrapolate\" # or pad\n",
    "\n",
    "if Sk_type == \"shearlet\":\n",
    "    print(\"Shearlet decomposition\")\n",
    "    folder = \"./dependencies/basisFunctions/\"\n",
    "    file = f\"{room}_tau{S}.mat\"\n",
    "\n",
    "    # TamaÃ±o diccionario // TamaÃ±o imagen interpolada\n",
    "    M, N  = 128, 128\n",
    "    # Imagen tamaÃ±o:\n",
    "    # M0, N0 = 100, 100\n",
    "\n",
    "    # Seleccionar subimage \n",
    "    Tstart = 0\n",
    "    Tend = None\n",
    "\n",
    "    build_dict = dict(Sk_type=Sk_type)\n",
    "\n",
    "elif Sk_type == \"boostlet\":\n",
    "    print(\"Boostlet decomposition\")\n",
    "\n",
    "    n_thetas = 7\n",
    "\n",
    "    # TamaÃ±o diccionario // TamaÃ±o imagen interpolada\n",
    "    M, N  = 128, 128\n",
    "    # Imagen tamaÃ±o:\n",
    "    M0, N0 = 100, 100\n",
    "\n",
    "    # Seleccionar subimage \n",
    "    Tstart = 0\n",
    "    Tend = Tstart+M0\n",
    "\n",
    "    folder = \"./dependencies/basisFunctions/boostlets\"\n",
    "    file = f\"boostlets_N_{N}_S_{S}_nthetas_{n_thetas}.mat\"\n",
    "    build_dict = dict(Sk_type=Sk_type, n_thetas=n_thetas, N=N, S=S)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar diccionario e imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- LOAD Dictionary -----------------------\n",
    "\n",
    "Sk = load_sk(folder, file, build_dict)\n",
    "print(Sk.shape)\n",
    "extr_size = Sk.shape[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- LOAD Image ---------------------------\n",
    "folder = \"./dependencies/measurementData\"\n",
    "file = room+\"RIR.mat\"\n",
    "file_path = os.path.join(folder, file)\n",
    "print(\"Image loaded:\")\n",
    "print(file_path)\n",
    "\n",
    "# Load full image and select a subimage to apply decomposition\n",
    "full_image = load_DB_ZEA(file_path)[0]\n",
    "orig_image = full_image[Tstart:Tend, :N0]\n",
    "\n",
    "mask0, _ = rand_downsamp_RIR(orig_image.shape, ratio_t=1, ratio_x=ratio_undersampling)\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(orig_image[Tstart:Tstart+100, :])\n",
    "ax[1].imshow((orig_image*mask0)[Tstart:Tstart+100, :])\n",
    "\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrapolation // Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Extrapolation\n",
    "# ----------------------------------------------------\n",
    "\n",
    "extr_size = Sk.shape[:2]\n",
    "imOps = ImageOps(orig_image.shape, mask=mask0, extrap_shape=extr_size, mode=extrap_mode) \n",
    "\n",
    "image = imOps.expand_image(orig_image)\n",
    "mask = imOps.get_mask(image)\n",
    "\n",
    "print(image.shape)\n",
    "print(mask.shape)\n",
    "\n",
    "images = [orig_image, image, mask*image]\n",
    "titles = ['Original Image', 'Expanded Image', 'Masked image']\n",
    "fig, ax = plt.subplots(1, len(images), figsize=(18, 6))\n",
    "for i in range(len(images)):\n",
    "    ax[i].imshow(images[i][:128,:])\n",
    "    ax[i].set_title(titles[i])\n",
    "    ax[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Proyection\n",
    "# ----------------------------------------------------\n",
    "image = mask*image\n",
    "alphas = ffst(image, Sk)\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(image)\n",
    "ax[1].imshow(mask*image)\n",
    "\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "plt.show()\n",
    "# ----------------------------------------------------\n",
    "# Pareto\n",
    "# ----------------------------------------------------\n",
    "\n",
    "beta_set = np.logspace(-2.5, -1, 50)\n",
    "beta_star, Jcurve = computePareto(image, mask, Sk, beta_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------------------------------\n",
    "# ISTA recovery\n",
    "# ----------------------------------------------------\n",
    "epsilon = 9.4e-6\n",
    "alpha = ista(image, mask, Sk, beta=beta_star, epsilon=epsilon, max_iterations=15 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover inpainted image from sparse coefficients (Eq. 19)\n",
    "image_recov = iffst(alpha, Sk)\n",
    "final_image = imOps.recover_image(image_recov)\n",
    "\n",
    "images = [orig_image[:100,:], (orig_image*mask0)[:100,:], final_image[:100,:]]\n",
    "titles = ['Original Image', 'Masked Image', 'Final reconst image']\n",
    "fig, ax = plt.subplots(1, len(images), figsize=(18, 6))\n",
    "for i in range(len(images)):\n",
    "    ax[i].imshow(images[i])\n",
    "    ax[i].set_title(titles[i])\n",
    "    ax[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FNOs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
